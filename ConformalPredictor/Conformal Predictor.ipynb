{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conformal prediction implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we handle the 0/0 situation by setting the score to Zero. 0/0 situation can arise only when there are training datapoints of different labels at the same location as the test datapoint. Given the situation it is highly likely that the label datapoint will have same label as one of them. Setting the conformity score to lowest possible value ensures that all these datapoints they have the highest possible pessimistic rank and the same p-value which indicates equal probability of the label being same as the test data points.\n",
    "\n",
    "In below implmentation some superflous calculations were avoided, such as :\n",
    "1. Repetative calculation of distances for test set for each iteration of postulated label:   \n",
    "    This has been handled by creating as distance matrix of distance to nearest point of same label and different label\n",
    "    at the beginning for all points in y_train.\n",
    "    On further iterations over the test datapoints a copy of matrix is made and the distances are updated only if the test data\n",
    "    point is the nearest point of same label or different label.\n",
    "2. Calculation of scores for all datapoints:   \n",
    "    It is unnecessary to calculate the ranks for each conformity score as we only need the rank of the test datapoint. This has \n",
    "    been acheived by incrementing the rank while comparing the conformity scores if they are found to be lower or equal to the \n",
    "    caluated conformity score of the test datapoint for the considered postulated label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring all import statements\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate and return Euclidean Distance between two points\n",
    "#Input: arr1(numpy array), arr2(numpy array)\n",
    "def distance(arr1,arr2):\n",
    "    dist_sq=0\n",
    "    for i in range(len(arr1)):\n",
    "        dist_sq += (arr1[i] - arr2[i])**2\n",
    "    dist = np.sqrt(dist_sq)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate p-values for each label for sample passed as input\n",
    "#conformity score calculated by the formula:\n",
    "#(the distance to the nearest sample of a different class/the distance to the nearest sample of the same class)\n",
    "#we pass the X_train,y_train and the default distance matrix for the test set along with the sample\n",
    "def pvalue(sample,distances,X_train,y_train):\n",
    "    labels = np.unique(y_train)\n",
    "    label_count = len(labels)\n",
    "    scores = np.zeros(np.shape(y_train)[0]+1)\n",
    "    pvalues = np.zeros(label_count)\n",
    "    for i in range(len(labels)):\n",
    "        #Considering as postulated label\n",
    "        postulated_label = i\n",
    "        distances_run = np.copy(distances)\n",
    "        for j in range(len(X_train)):\n",
    "            dist = 0\n",
    "            distance_to_nearest_diff = math.inf\n",
    "            distance_to_nearest_same = math.inf\n",
    "            if postulated_label == y_train[j]:\n",
    "                dist = distance(sample,X_train[j])\n",
    "                if dist <  distance_to_nearest_same :\n",
    "                    distance_to_nearest_same = dist\n",
    "            else:\n",
    "                dist = distance(sample,X_train[j])\n",
    "                if dist <  distance_to_nearest_diff :\n",
    "                    distance_to_nearest_diff = dist      \n",
    "            if distance_to_nearest_diff < distances_run[j][0]:\n",
    "                distances_run[j][0] =   distance_to_nearest_diff\n",
    "            if distance_to_nearest_same < distances_run[j][1]: \n",
    "                distances_run[j][1] =    distance_to_nearest_same       \n",
    "        dist=0\n",
    "        distance_to_nearest_diff = math.inf\n",
    "        distance_to_nearest_same = math.inf\n",
    "        for j in range(len(X_train)):\n",
    "            if postulated_label == y_train[j]:\n",
    "                dist = distance(sample,X_train[j])\n",
    "                if dist <  distance_to_nearest_same :\n",
    "                    distance_to_nearest_same = dist\n",
    "            else:\n",
    "                dist = distance(sample,X_train[j])\n",
    "                if dist <  distance_to_nearest_diff :\n",
    "                    distance_to_nearest_diff = dist\n",
    "            distances_run[len(X_train)][0] =    distance_to_nearest_diff\n",
    "            distances_run[len(X_train)][1] =    distance_to_nearest_same\n",
    "        for j in range(len(X_train)+1):\n",
    "            #Handling Zero Division errors\n",
    "            if (distances_run[j][0] == 0) and (distances_run[j][1] == 0):\n",
    "                scores[j] = 0\n",
    "            if distances_run[j][1] == 0 :\n",
    "                scores[j] = math.inf\n",
    "            elif distances_run[j][0] == 0 :\n",
    "                scores[j] = 0\n",
    "            else : \n",
    "                scores[j] = ( distances_run[j][0]/ distances_run[j][1])\n",
    "        rank = 1\n",
    "        sample_score = scores[len(X_train)]\n",
    "        for l in range(len(X_train)):\n",
    "            if (sample_score > scores[l] ) or (sample_score == scores[l]) :\n",
    "                rank += 1\n",
    "            p = rank/(len(X_train)+1)\n",
    "            pvalues[i] = p        \n",
    "            \n",
    "    return pvalues\n",
    "        \n",
    "#The function is call to return the conformal predictions    \n",
    "#Below function takes the samples(s) as input and returns a matrix of p-value(s) for each sample per postulated label. \n",
    "#Each column representing each label\n",
    "#It calls the pvalue function defined above to calculate the p-values\n",
    "#parameters to pass while calling the function are set of new sample(s),X_train,y_train\n",
    "def conformal_predictor(new_sample,X_train,y_train):\n",
    "    labels = np.unique(y_train)\n",
    "    label_count = len(labels)\n",
    "    distances = np.zeros((len(X_train)+1,2))\n",
    "    scores = np.zeros(np.shape(y_train)[0]+1)\n",
    "    pvalues = np.zeros(label_count)\n",
    "    for j in range(len(X_train)):\n",
    "        dist = 0\n",
    "        distance_to_nearest_diff = math.inf\n",
    "        distance_to_nearest_same = math.inf\n",
    "        for k in range(len(X_train)):\n",
    "            if j != k:\n",
    "                if y_train[j] == y_train[k]:\n",
    "                    dist = distance(X_train[j],X_train[k])\n",
    "                    if dist <  distance_to_nearest_same :\n",
    "                        distance_to_nearest_same = dist\n",
    "                else:\n",
    "                    dist = distance(X_train[j],X_train[k])\n",
    "                    if dist <  distance_to_nearest_diff :\n",
    "                        distance_to_nearest_diff = dist\n",
    "        distances[j][0] = distance_to_nearest_diff\n",
    "        distances[j][1] = distance_to_nearest_same\n",
    "    distances[len(X_train)][0] = math.inf\n",
    "    distances[len(X_train)][1] = math.inf    \n",
    "    \n",
    "    length = len(new_sample)\n",
    "    results = []\n",
    "    for i in range(length):\n",
    "        sample = new_sample[i]\n",
    "        result = pvalue(sample,distances,X_train,y_train)\n",
    "        results.append(result)\n",
    "   \n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IRIS dataset prediction using Conformal Prediction implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "iris_data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the IRIS dataset into train and test data sets using random_state\n",
    "from sklearn.model_selection import train_test_split\n",
    "Iris_X_train, Iris_X_test, Iris_y_train, Iris_y_test = train_test_split(iris_data.data, iris_data.target,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix of p-values:\n",
      "\n",
      "[array([0.00884956, 0.00884956, 0.73451327]), array([0.74336283, 0.00884956, 0.00884956]), array([0.00884956, 0.00884956, 0.54867257]), array([0.71681416, 0.00884956, 0.00884956]), array([0.00884956, 0.00884956, 0.17699115]), array([0.00884956, 0.00884956, 0.38053097]), array([0.7079646 , 0.00884956, 0.00884956]), array([0.81415929, 0.00884956, 0.00884956]), array([0.00884956, 0.00884956, 0.59292035]), array([0.75221239, 0.00884956, 0.00884956]), array([0.88495575, 0.00884956, 0.00884956]), array([0.00884956, 0.00884956, 0.32743363]), array([0.74336283, 0.00884956, 0.00884956]), array([0.86725664, 0.00884956, 0.00884956]), array([0.00884956, 0.00884956, 0.47787611]), array([0.00884956, 0.46902655, 0.00884956]), array([0.00884956, 0.2920354 , 0.00884956]), array([0.00884956, 0.07079646, 0.02654867]), array([0.00884956, 0.00884956, 0.73451327]), array([0.00884956, 0.00884956, 0.59292035]), array([0.00884956, 0.00884956, 0.45132743]), array([0.69911504, 0.00884956, 0.00884956]), array([0.00884956, 0.05309735, 0.0619469 ]), array([0.81415929, 0.00884956, 0.00884956]), array([0.00884956, 0.69026549, 0.00884956]), array([0.00884956, 0.02654867, 0.07079646]), array([0.00884956, 0.5840708 , 0.00884956]), array([0.66371681, 0.00884956, 0.00884956]), array([0.00884956, 0.24778761, 0.00884956]), array([0.00884956, 0.00884956, 0.5840708 ]), array([0.00884956, 0.74336283, 0.00884956]), array([0.00884956, 0.7079646 , 0.00884956]), array([0.00884956, 0.08849558, 0.01769912]), array([0.80530973, 0.00884956, 0.00884956]), array([0.7079646 , 0.00884956, 0.00884956]), array([0.00884956, 0.24778761, 0.00884956]), array([0.88495575, 0.00884956, 0.00884956]), array([0.00884956, 0.53982301, 0.00884956])]\n",
      "\n",
      "\n",
      "The average false p-value for the Nearest Neighbour conformal predictor applied to the IRIS dataset: 0.010945505356311143\n"
     ]
    }
   ],
   "source": [
    "#Calling conformal prediction function for the test set of IRIS dataset\n",
    "cp_iris = conformal_predictor(Iris_X_test,Iris_X_train,Iris_y_train)\n",
    "print(\"Matrix of p-values:\\n\")\n",
    "print(cp_iris)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Following loop calculates the total false p-value for predictions on the test dataset\n",
    "p_error =0\n",
    "count = 0\n",
    "labels = np.unique(iris_data.target)\n",
    "for i in range(len(Iris_y_test)):\n",
    "    for j in range(len(labels)):\n",
    "        if labels[j] != Iris_y_test[i]:\n",
    "            p_error += cp_iris[i][j]\n",
    "            count += 1 \n",
    "            \n",
    "# Calculating the average False p Value             \n",
    "avg_false_p_value = p_error/count\n",
    "print(\"The average false p-value for the Nearest Neighbour conformal predictor applied to the IRIS dataset:\", avg_false_p_value )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the validity of the conformal predictor predicting IRIS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the predictions of IRIS Dataset using Conformal Prediction is : 97.36842105263158 %\n"
     ]
    }
   ],
   "source": [
    "#In this case while validating we are considering the label with highest p-value as the predicted label\n",
    "validate = np.empty(len(Iris_y_test))\n",
    "for i in range(len(Iris_y_test)):\n",
    "    p = 0\n",
    "    predicted_label = 0\n",
    "    for j in range(len(labels)):\n",
    "        if cp_iris[i][j] > p :\n",
    "            p = cp_iris[i][j]\n",
    "            predicted_label = j\n",
    "    if Iris_y_test[i] == predicted_label:\n",
    "        validate[i] = 1\n",
    "    else:\n",
    "        validate[i] = 0\n",
    "print(\"The accuracy of the predictions of IRIS Dataset using Conformal Prediction is :\", np.mean(validate)*100,\"%\")        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ionosphere dataset prediction using Conformal Prediction implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading ionosphere data\n",
    "ion = np.genfromtxt(\"ionosphere.txt\", delimiter=\",\")\n",
    "ion[1:33]\n",
    "data = ion[:,0:34]\n",
    "target = ion[:,34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the Ionosphere dataset to train and test data sets using random_state\n",
    "from sklearn.model_selection import train_test_split\n",
    "Ion_X_train, Ion_X_test, Ion_y_train, Ion_y_test = train_test_split(data,target,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average false p-value for the Nearest Neighbour conformal predictor applied to ionosphere.txt: 0.04773588154269979\n"
     ]
    }
   ],
   "source": [
    "#Calling conformal prediction function for the test set of Ionosphere dataset\n",
    "cp_ion = conformal_predictor(Ion_X_test,Ion_X_train,Ion_y_train)\n",
    "p_error =0\n",
    "count = 0\n",
    "labels = np.unique(target)\n",
    "\n",
    "#Following loop calculates the total false p-value for the predictions on test dataset\n",
    "for i in range(len(Ion_y_test)):\n",
    "    for j in range(len(labels)):\n",
    "        if labels[j] != Ion_y_test[i]:\n",
    "            p_error += cp_ion[i][j]\n",
    "            count += 1\n",
    "            \n",
    "# Calculating the average False p Value              \n",
    "avg_false_p_value = p_error/count\n",
    "print(\"The average false p-value for the Nearest Neighbour conformal predictor applied to ionosphere.txt:\", avg_false_p_value )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the validity of the conformal predictor predicting Ionosphere Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the predictions of Ionosphere Dataset using Conformal Prediction is : 63.63636363636363 %\n"
     ]
    }
   ],
   "source": [
    "#In this case while validating we are considering the label with highest p-value as the predicted label\n",
    "validate = np.empty(len(Ion_y_test))\n",
    "for i in range(len(Ion_y_test)):\n",
    "    p = 0\n",
    "    predicted_label = 0\n",
    "    for j in range(len(labels)):\n",
    "        if cp_ion[i][j] > p :\n",
    "            p = cp_ion[i][j]\n",
    "            predicted_label = j\n",
    "    if Ion_y_test[i] == predicted_label:\n",
    "        validate[i] = 1\n",
    "    else:\n",
    "        validate[i] = 0\n",
    "print(\"The accuracy of the predictions of Ionosphere Dataset using Conformal Prediction is :\", np.mean(validate)*100,\"%\")        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with Conformal prediction with Conformity score = Distance to nearest sample of different class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate p-values for each label for sample passed as input\n",
    "#conformity score is the distance to the nearest sample of a different class\n",
    "#we pass the X_train, y_train and the default distance matrix for the test set along with the sample\n",
    "def pvalue2(sample,distances,X_train,y_train):\n",
    "    labels = np.unique(y_train)\n",
    "    label_count = len(labels)\n",
    "    scores = np.zeros(np.shape(y_train)[0]+1)\n",
    "    pvalues = np.zeros(label_count)\n",
    "    for i in range(len(labels)):\n",
    "        #Considering as postulated label\n",
    "        postulated_label = i\n",
    "        distances_run = np.copy(distances)\n",
    "        for j in range(len(X_train)):\n",
    "            dist = 0\n",
    "            distance_to_nearest_diff = math.inf\n",
    "            if postulated_label != y_train[j]:\n",
    "                dist = distance(sample,X_train[j])\n",
    "                if dist <  distance_to_nearest_diff :\n",
    "                    distance_to_nearest_diff = dist      \n",
    "            if distance_to_nearest_diff < distances_run[j][0]:\n",
    "                distances_run[j][0] =   distance_to_nearest_diff    \n",
    "        dist=0\n",
    "        distance_to_nearest_diff = math.inf\n",
    "        for j in range(len(X_train)):\n",
    "            if postulated_label != y_train[j]:\n",
    "                dist = distance(sample,X_train[j])\n",
    "                if dist <  distance_to_nearest_diff :\n",
    "                    distance_to_nearest_diff = dist\n",
    "            distances_run[len(X_train)][0] =    distance_to_nearest_diff\n",
    "        scores = np.copy(distances_run)\n",
    "        rank = 1\n",
    "        sample_score = scores[len(X_train)]\n",
    "        for l in range(len(X_train)):\n",
    "            if (sample_score > scores[l] ) or (sample_score == scores[l]) :\n",
    "                rank += 1\n",
    "            p = rank/(len(X_train)+1)\n",
    "            pvalues[i] = p        \n",
    "            \n",
    "    return pvalues\n",
    "        \n",
    "#The function is call to return the conformal predictions    \n",
    "#Below function takes the samples(s) as input and returns a matrix of p-value(s) for each sample per postulated label. \n",
    "#Each column representing each label\n",
    "#It calls the pvalue function defined above to calculate the p-values\n",
    "#parameters to pass while calling the function are set of new sample(s),X_train,y_train\n",
    "def conformal_predictor2(new_sample,X_train,y_train):\n",
    "    labels = np.unique(y_train)\n",
    "    label_count = len(labels)\n",
    "    distances = np.zeros((len(X_train)+1,1))\n",
    "    scores = np.zeros(np.shape(y_train)[0]+1)\n",
    "    pvalues = np.zeros(label_count)\n",
    "    for j in range(len(X_train)):\n",
    "        dist = 0\n",
    "        distance_to_nearest_diff = math.inf\n",
    "        distance_to_nearest_same = math.inf\n",
    "        for k in range(len(X_train)):\n",
    "            if j != k:\n",
    "                if y_train[j] != y_train[k]:\n",
    "                    dist = distance(X_train[j],X_train[k])\n",
    "                    if dist <  distance_to_nearest_diff :\n",
    "                        distance_to_nearest_diff = dist\n",
    "        distances[j][0] = distance_to_nearest_diff\n",
    "    distances[len(X_train)][0] = math.inf    \n",
    "    \n",
    "    length = len(new_sample)\n",
    "    results = []\n",
    "    for i in range(length):\n",
    "        sample = new_sample[i]\n",
    "        result = pvalue2(sample,distances,X_train,y_train)\n",
    "        results.append(result)\n",
    "   \n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the scores for Iris dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix of p-values:\n",
      "\n",
      "[array([0.01769912, 0.01769912, 0.36283186]), array([0.72566372, 0.03539823, 0.03539823]), array([0.16814159, 0.16814159, 0.97345133]), array([0.99115044, 0.08849558, 0.08849558]), array([0.01769912, 0.01769912, 0.07964602]), array([0.15044248, 0.15044248, 0.65486726]), array([0.97345133, 0.0619469 , 0.0619469 ]), array([0.72566372, 0.01769912, 0.01769912]), array([0.01769912, 0.01769912, 0.30088496]), array([0.71681416, 0.01769912, 0.01769912]), array([0.88495575, 0.01769912, 0.01769912]), array([0.04424779, 0.04424779, 0.38938053]), array([0.69911504, 0.01769912, 0.01769912]), array([0.82300885, 0.01769912, 0.01769912]), array([0.03539823, 0.03539823, 0.40707965]), array([0.01769912, 0.27433628, 0.01769912]), array([0.14159292, 0.56637168, 0.14159292]), array([0.04424779, 0.08849558, 0.04424779]), array([0.03539823, 0.03539823, 0.83185841]), array([0.01769912, 0.01769912, 0.38053097]), array([0.0619469 , 0.0619469 , 0.53982301]), array([0.71681416, 0.04424779, 0.04424779]), array([0.08849558, 0.08849558, 0.07964602]), array([0.7079646 , 0.01769912, 0.01769912]), array([0.01769912, 0.50442478, 0.01769912]), array([0.03539823, 0.03539823, 0.07964602]), array([0.01769912, 0.27433628, 0.01769912]), array([0.7079646 , 0.04424779, 0.04424779]), array([0.03539823, 0.13274336, 0.03539823]), array([0.03539823, 0.03539823, 0.52212389]), array([0.01769912, 0.54867257, 0.01769912]), array([0.01769912, 0.43362832, 0.01769912]), array([0.08849558, 0.2300885 , 0.08849558]), array([0.76106195, 0.01769912, 0.01769912]), array([0.96460177, 0.0619469 , 0.0619469 ]), array([0.03539823, 0.20353982, 0.03539823]), array([0.88495575, 0.01769912, 0.01769912]), array([0.01769912, 0.39823009, 0.01769912])]\n",
      "\n",
      "\n",
      "The average false p-value for the Nearest Neighbour conformal predictor applied to the IRIS dataset: 0.04541220307405684\n"
     ]
    }
   ],
   "source": [
    "cp2_iris = conformal_predictor2(Iris_X_test,Iris_X_train,Iris_y_train)\n",
    "print(\"Matrix of p-values:\\n\")\n",
    "print(cp2_iris)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Following loop calculates the total false p-value for predictions on the test dataset\n",
    "p_error =0\n",
    "count = 0\n",
    "labels = np.unique(iris_data.target)\n",
    "for i in range(len(Iris_y_test)):\n",
    "    for j in range(len(labels)):\n",
    "        if labels[j] != Iris_y_test[i]:\n",
    "            p_error += cp2_iris[i][j]\n",
    "            count += 1 \n",
    "            \n",
    "# Calculating the average False p Value             \n",
    "avg_false_p_value = p_error/count\n",
    "print(\"The average false p-value for the Nearest Neighbour conformal predictor applied to the IRIS dataset:\", avg_false_p_value )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the predictions of IRIS Dataset using Conformal Prediction is : 94.73684210526315 %\n"
     ]
    }
   ],
   "source": [
    "#In this case while validating we are considering the label with highest p-value as the predicted label\n",
    "validate = np.empty(len(Iris_y_test))\n",
    "for i in range(len(Iris_y_test)):\n",
    "    p = 0\n",
    "    predicted_label = 0\n",
    "    for j in range(len(labels)):\n",
    "        if cp2_iris[i][j] > p :\n",
    "            p = cp2_iris[i][j]\n",
    "            predicted_label = j\n",
    "    if Iris_y_test[i] == predicted_label:\n",
    "        validate[i] = 1\n",
    "    else:\n",
    "        validate[i] = 0\n",
    "print(\"The accuracy of the predictions of IRIS Dataset using Conformal Prediction is :\", np.mean(validate)*100,\"%\")        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations about the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are duplicate datapoints in the IRIS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.8, 2.7, 5.1, 1.9])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data.data[101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.8, 2.7, 5.1, 1.9])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data.data[142]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data.target[101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data.target[142]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second column in ionosphere dataset has no variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ion[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results at a glance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "– the average false p-value for the Nearest Neighbour conformal predictor applied to the iris dataset: 0.010829063809967407\n",
    "\n",
    "– the average false p-value for the Nearest Neighbour conformal predictor applied to ionosphere.txt:  0.04429235537190089"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations on method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of conformal prediction is compute intensive and takes longer as the number of observations and possible labels increases.\n",
    "\n",
    "There is not much difference in accuracy of prediction on the Iris dataset using Conformal Prediction with different conformity scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://scikit-learn.org/stable/index.html    \n",
    "\n",
    "2. https://numpy.org/doc/stable/\n",
    "\n",
    "3. https://docs.python.org/3/library/math.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
